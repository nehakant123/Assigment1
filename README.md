**Project:-GESTURE BASED TEXT RECOGNITION**

This project demonstrates one way in which computers can interpret human gestures. In today's world, we see advanced versions of this technology in applications such as **Tesla's** 
self-driving cars, which use similar deep learning programs to automate driving, and **recommendation systems** on various apps that suggest popular web series or movies. This project 
takes us on a journey through the basics of these advanced systems, providing a foundational understanding of how they are developed.
This project first enhanced my Python coding skills and then taught me the basics of machine learning. The best part was learning about **Convolutional Neural Networks (CNNs)** and 
implementing various **OpenCV and MediaPipe projects**, such as creating a **face mesh** and a **hand detector**.

This project operates in a straightforward manner. First, it activates the computer's camera and creates a virtual canvas using OpenCV and various MediaPipe packages. Users can then draw or write on this canvas within the range of the dataset included in the CNN module. After the input is provided, the CNN model trains the neural network and processes the input to produce the desired output.This github repo conatins many assignments which are also a important part of this project.Assignment 3 is a crucial component of this project, as it delves into the workings of Convolutional Neural Networks (CNNs) on various datasets, including CIFAR-100, CIFAR-10, and Fashion MNIST.
